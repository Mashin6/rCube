%\VignetteIndexEntry{Guide to the "rCube" package}
%\VignettePackage{rCube}
%\VignetteEngine{knitr::knitr}

\documentclass{article}

<<knitr, echo=FALSE, results="hide">>=
library("knitr")
opts_chunk$set(tidy=FALSE,dev="png",fig.show="hide",
               fig.width=4,fig.height=4.5,
               message=FALSE)
@ 

<<style, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

\title{rCube - RNA-Rates in R}
\author{Leonhard Wachutka$^{1,*}$, Carina Demel$^{2}$, Julien Gagneur$^{1}$ \\
[1em] \small{$^{1}$ Department of Informatics, Technical University of Munich, Munich, Germany} \\
\small{$^{2}$ Max Planck Institute for biophysical Chemistry, G\"ottingen, Germany} \\
\small{\texttt{$^*$ wachutka (at) in.tum.de}}
}


\begin{document}


\maketitle

%\noindent This vignette describes version \Sexpr{packageDescription("rCube")$Version} of the \Rpackage{rCube} package.

%\noindent Last revision of this document: \StrMid{$Date: 2017-07-25 $}{8}{18}

<<options,results="hide",echo=FALSE>>=
options(digits=3, width=80, prompt=" ", continue=" ")
@


\begin{abstract}
% A common problem of RNA-Seq experiments is the normalization of different
% samples, especially when they were also treated differently. A special case is
% the 4sU-labeling and purification, followed by deep-sequencing, where two libraries are generated
% from each RNA fraction: First, in one part of the fraction, the 4sU-labeled
% RNAs are pulled down and gives the labeled (``L") fraction of the experiment for
% library preparation. Second, the total RNA (labeled and unlabeled, ``T") is used
% for the preparation of another RNA-Seq library. As the RNA amount for library
% preparation is usually stringent, the sequencing results do not reflect
% reality. Here, we have to account for the sequencing depth of different samples
% and especially adjust the ratio of Labeled to Total RNA-Seq libraries.

{\color{red}rCube} provides a framework for the estimation of {\textcolor{red}R}NA metabolism {\textcolor{red}R}ates in {\textcolor{red}R} (${\color{red}R^3}$). The rCube package complements the recently published transient transcriptome sequencing (TT-seq) protocol. It has been shown, that 4sU-labeling and subsequent purification of RNA allows to monitor local RNA synthesis. Therefore, the information from TT-seq/4sU-seq and total RNA-seq samples is used to model RNA synthesis, splicing, and degradation rates based on first-order kinetics. The rCube package works on count data and provides a series of functionalities to extract them from the desired features. It allows to extract junctions and constitutive exons from feature annotations,
count reads from BAM-files, and normalize different samples against each other using a variety of different methods.

\vspace{1em}
  
  \textbf{rCube version:} \Sexpr{packageDescription("rCube")$Version}

  \vspace{1em}
  
  \begin{center}
    \begin{tabular}{ | l | }
      \hline 
      If you use rCube in published research, please cite:  \\
      \\
      B. Schwalb, M. Michel, B. Zacher, K. Fr\"uhauf, C. Demel, A. Tresch, J. Gageur, and P. Cramer: \\ 
      TT-seq maps the human transient transcriptome. \\
      Science (2016). doi:10.1126/science.aad9841 \cite{Schwalb2016} \\
      \hline 
    \end{tabular}
  \end{center}
  
\end{abstract}


\tableofcontents


%--------------------------------------------------
\section{Background}
%--------------------------------------------------


As described in .... 4sU-seq allows to monitor changes in the RNA metabolism. If cells are exposed to 4sU, they rapidly take up this Uridine analog and incorporate it into newly-synthesized RNAs. This way, newly-synthesized RNAs are labeled and can be extracted from the total RNA in the sample. The longer the labeling time, e.i. the time from 4sU addition to harvesting the cells, the bigger is the proportion of labeled RNAs among all RNAs.


explain the  why we have spike ins (diagram?)
Artificial RNA spike-in sequences can be used to adjust for global sequencing variations between samples. One source of variation is the sequencing depth. Even replicates from the same experimental condition may exhibit different read counts based on how deep the samples were sequenced. These variations (up to biological variations) can be overcome by normalization to sequencing depth.
In a typical RNA-seq experiment, one wants to compare different samples. After extracting the RNA from the cells, the same starting material is used for the library prepartion, therefore the information is lost, if cells from different samples were expressing different amounts of RNA. Adding the same volumes of spike-ins to a defined number of cells can help to resolve this problem. In our case, we additionally want to rescale 4sU-labeled and total RNA-seq samples, so that the ratio of labeled RNA to total RNA read counts reflects the ratio of labeled RNA to total RNA amounts in the cell.
%The External RNA Control Consortium (ERCC) is providing a set artifical RNA sequences that do not map to any known genome.


 explain time series vs only label total 

 ref to TTseq
 \cite{Schwalb2016}

 ref to MSB
 In another study, we
\cite{Michel2017} 


 define synthesis, splicing, decay rate

 define the read classifications: junction reads E-E, E-I, I-E junction 

%--------------------------------------------------
\section{Getting started} \label{GettingStarted}
%--------------------------------------------------

This vignette provides a pipeline how to...
starting from BAM files...
You will learn how to estimate sample specific sequencing
depths and cross-contamination rates from spike-in counts. These values can be
used to normalize gene expression values obtained by RNA-Seq and thus estimate
gene-specific synthesis and degradation rates. 
By extracting reads spanning junctions, splicing times can be estimated. For 
more robust estimation, multiple samples with different labeling times are
taken into account.
Before starting, the package must be loaded by:

<<LoadingLibrary, echo=TRUE, results="hide">>=
library("rCube")
@

\subsection{Example Data}

The \texttt{inst/extdata} of the \textit{rCube} package provides two example data sets that 
should illustrate the two different functionalities of rCube:

The first example data set, ``Jurkat'', contains bam files from resting and activated Jurkat T-cells for TT-seq and RNA-seq samples. The bamfiles are restricted to the FOS gene (chr14:75278000-75283000) and the artifical spike-ins, subsampled to reduce file size. The full data sets are published in \cite{Michel2017}. This example data is used to demonstrate the spike-ins normalization method, and the estimation of synthesis and degradation rates for individual 4sU-labeled (TT-seq) and total RNA-seq pairs.

The second data set , ...

%--------------------------------------------------
\section{Conditional synthesis and degradation rates for Jurkat data}
%--------------------------------------------------

Example data sets from a T-cell activation experiment are stored in the \texttt{inst/extdata} of the \textit{rCube} package.
In this part of the vignette, we will demonstrate 
\begin{itemize}
\item how reads can be counted for (constitutive) exons and spike-ins,
\item how the samples are normalized against each other based on the spike-in read counts,
\item how synthesis and degradation rates are obtained for (constitutive) exons
\item how gene-specific rates are obtained from exon-specific rates
\end{itemize}

\subsection{Gene model}
working on exons/introns/genes...
The estimation of synthesis and degradation rates with the \textit{rCube} package relies on read counts.
Dependent on the features, for which read counts are provided, the rates can reflect synthesis rates of exons, introns, or full genes. 
Especially degradation rates may differ between exons and introns. 
Therefore, the features, which should be used to estimate synthesis and degradation rates, 
and for which read counts are provided or should be obtained, need to be provided as a \Rclass{GRanges} object.

Due to numerous transcript isoforms per gene, and the arising problem that for 
some bases their exonic or intronic nature cannot be unambigously identified, 
we propose to use the model of constitutive exons/introns from \cite{Bullard2010}.
Hereby, all bases, that belong to an exon/intron in all (annotated) transcript 
isoforms of the same gene, are thought to be part of "constitutive" exons/introns.
In the following, we have an example annotation from the FOS gene (not comprehensive) to illustrate how constitutive exons can be extracted from an exon annotation.

<<constitutiveExons, echo=TRUE>>==
data("exampleExons")
exampleExons
constitutiveExons <- createConstitutiveFeaturesGRangesFromGRanges(exampleExons,
                                                                  BPPARAM=NULL,
                                                                  ncores=1)
constitutiveExons
@


<<plotConstExons, echo=FALSE, eval=TRUE, fig.width=7.5, fig.height=2.5, fig.show='asis'>>==
library(ggbio)
data("exampleExons")
elementMetadata(exampleExons) = data.frame("group"=elementMetadata(exampleExons)[,"transcript_id"])
elementMetadata(constitutiveExons) = data.frame("group"="constitutive")
gra2 = c(exampleExons, constitutiveExons)
levels(gra2$group) = c("isoform 1", "isoform 2", "constitutive")
gra2$group = relevel(gra2$group, ref="constitutive")
autoplot(gra2, aes(fill = group, group = group), geom = "alignment", group.selfish = TRUE, xlab="chromosome 14")
@

Please note, for the subsequent workflow it is not necessary to extract constitutive exons. Any kind of \Rclass{GRanges} object can be used as feature annotation (e.g. full genes, introns, ...).


\subsection{Experimental Design}

The rCube package works on \Rclass{rCubeExperiment} containers, that rely on the
\Rclass{SummerizedExperiment} class.
Objects of this class are used as input for the whole
workflow, starting from read counting, normalization, dispersion estimation, to rate estimation. Most of these steps return an updated and extended 
\Rclass{rCubeExperiment} object.

The \Robject{rowRanges} of the \Rclass{rCubeExperiment} is a \Rclass{GRanges} annotation of
features, for which RNA rates should be estimated. Experimental sample information
can be either provided by a experimental design matrix or this information can be extracted from
the BAM-file names (when they fulfil the required structure).

We first look at the experimental design file \texttt{experimentalDesign.txt}, that can be imported as a \Rclass{data.frame}.

<<ExperimentalDesign, echo=TRUE, eval=TRUE>>==
folder <- system.file("extdata/Jurkat", package='rCube')
folder
expDesign <- read.delim(file.path(folder, "experimentalDesign.txt"))
expDesign
@

Together with the feature annotation, for which we want to estimate synthesis and degradation rates, we can construct the \Rclass{rCubeExperiment}:
<<ExperimentalDesignFromFile, echo=TRUE>>==
exonCounts <- setupExperiment(constitutiveExons, designMatrix=expDesign, files=NULL)
class(exonCounts)
@

Alternatively, the experimental design matrix can be constructed from the bam file names internally, if they follow the following convention
\texttt{\{condition\}\_\{L|T\}\_\{labelingTime\}\_\{replicate\}.bam}

<<bamfiles, echo=TRUE>>==
bamfiles <- list.files(folder, pattern="*.bam$", full.names=TRUE)
basename(bamfiles)

exonCounts <- setupExperiment(constitutiveExons, designMatrix=NULL, files=bamfiles)
@

The individual information from the \Rclass{rCubeExperiment} can be assessed by:
<<expDesignAccessors, echo=TRUE>>==
# feature information
rowRanges(exonCounts)

# sample information
colData(exonCounts)

# read counts
assay(exonCounts)
@


The resulting \Rclass{rCubeExperiment} object can now be used to count reads.


\subsection{Counting}

For read countings, we use the \Rfunction{readGAlignmentPairs} in a parallel fashion:

<<Couting, echo=TRUE>>==
assay(exonCounts)

exonCounts <- countFeatures(exonCounts,
                            scanBamParam=ScanBamParam(flag=scanBamFlag(isSecondaryAlignment=FALSE)), 
                            BPPARAM=NULL, 
                            verbose=FALSE)
assay(exonCounts)
@


\subsection{Spike-ins}
The artifical spike-in annotations and labeling information can be loaded via:
<<spikeins, echo=TRUE>>==
data("spikeins")
data("spikeinLabeling")
spikeinLengths <- width(spikeins)
@

\subsection{Spike-in design}

An empty \Rclass{rCubeExperiment} for the artificial spike-ins additionally requires 
information about the length and the labeling status of each spikein, and can
be constructed as follows:

<<spikeindesign, echo=TRUE>>=
spikeinCounts <- setupExperimentSpikeins(rows=spikeins,
                                         designMatrix=expDesign,
                                         length=spikeinLengths,
                                         labelingState=spikeinLabeling)
@


\subsection{Spike-in counting}

%Please be aware, that our example data is stored in the \texttt{inst/extdata} of the \textit{rCube} package. Therefore, the \Robject{filename} in the \Rclass{rCubeExperiment}
%\Robject{colData} has to be adjusted to 
<<spikeincountsfilename, echo=FALSE>>=
colData(spikeinCounts)$filename <- bamfiles
@

%TODO this example does not work! :(
<<spikeincounts, echo=TRUE>>==
# spikeinCounts <- countSpikeins(spikeinCounts,
#                     scanBamParam=ScanBamParam(flag=scanBamFlag(isSecondaryAlignment=FALSE)),
#                     BPPARAM=NULL,
#                     verbose=FALSE)
assay(spikeinCounts)
@

+ diagnostic plot?


\subsection{Size factor based on spike-in}
\subsection{Estimate dispersion}
\subsection{Fit the rates}
\subsection{describe the different fitting functions}
\subsection{describe the class of the returned object (rCubeRates)}


%--------------------------------------------------
\section{Labeling time series}
%--------------------------------------------------

\subsection{Experimental Design}
\subsection{Read classification}
\subsection{Gene model}
(exon, into and junctions)
by gff
de novo + gff
\subsection{Counting}
\subsection{Spike-ins}
\subsection{Spike-in design}
\subsection{Spike-in counting}
\subsection{Size factor based on spike-in}
\subsection{Estimate dispersion}
\subsection{Fit the rates}
\subsection{describe the different fitting functions}
\subsection{describe the class of the returned object (rCubeRates)}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%### this part is old from before talking to julien:
 this part is old from before talking to julien:
 
 
\subsection{Input Data}
The rCube package works on \Rclass{rCubeExperiment} containers, that rely on the
\Rclass{SummerizedExperiment} class.
The \Robject{rowRanges} of the \Rclass{rCubeExperiment} is a \Rclass{GRanges} object of
features, for which RNA rates should be estimated. Experimental sample information
can be either provided by a design matrix or this information can be extracted from
the BAM-file names (when they fulfil the required structure). The file name should be a string containing condition, labelingTime (as integer), L/T sample information, and replicate (integer/string), separated by a "\_".
Then, an empty \Rclass{rCubeExperiment}, e.g. for the artificial spike-ins, can
be constructed as follows:
<<EmptyrCubeExperimentContainer, echo=TRUE>>=

data("designMatrix")

spikeinCounts <- setupExperimentSpikeins(rows=spikeins,
                                         designMatrix=designMatrix,
                                         length=spikeinLengths,
                                         labelingState=spikeinLabeling)
@
The \Rfunction{setupExperiment} can be used analogically for genes/exons/introns/junctions. Here, only the \Robject{rows} and either \Robject{designMatrix} or \Robject{files} has to be set. See also section \ref{Counting}.

The individual information from the \Rclass{rCubeExperiment} can be assessed by:
<<rCubeExperimentContainer, echo=TRUE>>=
# feature information
rowRanges(spikeinCounts)

# sample information
colData(spikeinCounts)

# read counts
assay(spikeinCounts)
@

\subsection{Read counting}\label{Counting}

All RNA rate estimations of this package rely on read counts. These can be either
provided as count matrices, or read counts can be obtained from BAM files using
the rCube pipeline.
<<counting, echo=TRUE>>=
#TODO 
@

Alternatively, count matrices can be assigned to the correctly formatted, empty
\Rclass{rCubeExperiment} object:
<<countAssignment, echo=TRUE, eval=FALSE>>=
#TODO 
@

% #TODO
% which section do we do::
% estimating gene specific syn dec rates (with spikein norm, based on const exons, then summarize rates)
% estimating splicing rates from labeling timecourse



%--------------------------------------------------
\section{Normalization of TT-seq/4sU-seq and RNA-Seq samples} \label{Normalization}
%--------------------------------------------------

The three possible normalization methods are described in detail below.

\subsection{Normalization by fitting a GLM to artifical spike-in read counts}

By normalization, we want to account for the sequencing depth of different samples
and especially adjust the ratio between Labeled to Total RNA-Seq libraries.
Additionally, the labeled RNA extraction is not perfect and some
unlabeled RNA may contaminate the labeled RNA fraction. As the gene-expression
also always varies a little bit for biological samples, read counts from real
genes might lead to confusing estimations. Therefore, we apply our
normalization approach only to artificial spike-ins from the External RNA 
Control Consortium (ERCC), for which
the initial amount of each spike-in is known and the same across all samples.
Some of the spike-ins were 4sU-labeled by in-vitro transcription, so the
cross-contamination of unlabeled spike-ins in labeled samples can be monitored.
The distribution of 4sU-labeled and unlabeld spike-ins among different samples
can be monitored with \Rfunction{plotSpikeinCountsVsSample}.

<<SpikeinDiagnosticPlot, fig.width=7, fig.height=4.5, echo=FALSE, results="hide">>=
data(spikeinCounts)
pdf("SpikeinDiagnosticPlot.pdf")
plotSpikeinCountsVsSample(spikeinCounts)
dev.off()
@

<<SpikeinDiagnosticPlotCode, echo=TRUE, eval=FALSE>>=
data(spikeinCounts)
plotSpikeinCountsVsSample(spikeinCounts)
@

\begin{figure}
\centering
\includegraphics[width=.6\textwidth]{SpikeinDiagnosticPlot.pdf}
\caption{
  \textbf{Spikein-vs-Sample-plot.} 
}
\label{plotSpikeinCountsVsSample}
\end{figure}

The goal of this package is to reliably estimate sequencing depths and
cross-contamination rates per sample, given 4sU- and total RNA-Seq data.

The sample specific parameters like sequencing depth and cross-contamination
rate are estimated from spike-in counts only. Therefore, we fit a
 generalized linear model (GLM) of the Negative Binomial family with a log link
 function.
The response of the GLM are the observed spike-in counts, and the terms that
specify the linear predictor of the response are comprised of:
\begin{itemize}
\item a sample specific factor (that reflects the sample specific sequencing
depth),
\item a labeled sample specific factor (that reflects the control for cross
contamination (only estimated for unlabeled spike-ins in labeled samples)), and
\item a spike-in specific factor to allow for some spike-in specific variation
e.g. due to sequence biases.
\end{itemize}
Additionally, the length of each spike-in is used as an offset, i.e. a known slope for the covariate.

<<SpikeinNormalization, echo=TRUE, eval=TRUE>>=
data(geneCounts)
data(spikeinCounts)
geneCounts <- estimateSizeFactors(geneCounts, spikeinCounts, method="spikeinGLM")
colnames(colData(geneCounts))
geneCounts$sequencing.depth
geneCounts$cross.contamination
@

Note, the cross-contamination value for all total RNA-seq samples is 1, as 100\%
of the unlabeled RNAs are supposed to be in the sample.
Additional fitting results are stored in the \Robject{metadata} of the resulting
\Rclass{rCubeExperiment} object.
<<SpikeinNormalizationMetadata, echo=TRUE, eval=FALSE>>=
metadata(geneCounts)
@

\subsection{Normalization using mean counts of artifical spike-ins}
%TODO

\subsection{Normalization using joint model}
%TODO

\newpage


%--------------------------------------------------
\section{Estimating gene-specific synthesis and degradation rates} \label{SynDec}
%--------------------------------------------------


Using the sample-specific values for sequencing depth and cross-contamination as estimated in the previous section, we can now normalize all the samples. It is especially important to bring labeled (4sU-seq/TT-seq) and total RNA-seq samples to comparable scales. Labeled and total RNA-seq samples can be sequenced at the same depth, and the same amount of RNA is used for library preparation, but the resulting read counts do not reflect the true ratio of labeled vs all RNAs in the cells, where the amount of newly-synthesized, labeled RNA should be much less than the total RNA amount. Therefore it is necessary to upscale the read counts from total RNA-seq samples compared to the labeled RNA read counts.

\subsection{Providing gene-wise dispersion estimates} \label{Dispersion}
Usually, read counts in different RNA-seq samples underly fluctuations due to biological or technical variances.
To take these fluctuations into account, we estimate each gene's dispersion.
For each gene, a single dispersion estimate for all 4sU-Seq samples and for all
Total RNA-Seq samples is needed. Here, we can use the method provided in the
DESeq2 package \cite{Love2014} The wrapper function \Rfunction{estimateSizeDispersions}
applies the DESeq algorithm to all genes, while separating the count table
according to the RNA-Seq protocol (labeled or total RNA). It is possible to
choose between all provided DESeq dispersion estimates, namely the genewise
maximum likelihood dispersion estimate (``dispGeneEst"), the smooth curve fitted
through the gene-wise disperion estimates (``dispFit") and the genewise
dispersion estimates shrunken towards the fitted curve (``dispMAP", default).
The input is an \Rclass{rCubeExperiment} object with read counts for the features of interest. The function returns an updated \Rclass{rCubeExperiment} object with two additional columns in the \Robject{rowRanges}, namely \Robject{dispersion\_L} and \Robject{dispersion\_T}.

%TODO leos dispersion is differently

<<DESeqDispersion, echo=TRUE, eval=TRUE>>=
geneCounts <- estimateSizeDispersions(geneCounts, method='DESeqDispMAP')
rowRanges(geneCounts)
@


\subsection{Feature-specific synthesis and degratation rate estimates}

After estimating sequencing depth and cross-contamination rates per sample (see Section \ref{Normalization}) and extracting feature-specific dispersion estimates (see Section \ref{Dispersion}), we can now estimate RNA synthesis and degradation rate for each feature and condition individually. Multiple replicates for the same condition can be used for a joint estimation. 
The user has to specify for which replicate or combination of replicates the results should be estimated. Therefore, the \Robject{replicate} parameter is a vector of all combinations that should be evaluated. For the joint estimation for multiple replicates, these have to be
given as a string separeted by a ``:''. In the following example, we will obtain individual results for replicate 1 and 2 and also results for a joint estimation.

<<SynDecEstimation, echo=TRUE, eval=FALSE>>=
rates <- estimateRateByFirstOrderKinetics(geneCounts,
                                          replicate=c(1, 2, "1:2"),
                                          method='single',
                                          BPPARAM=BiocParallel::MulticoreParam(1))
@


%--------------------------------------------------
\section{Estimating splicing times from junction read counts} \label{Splicing}
%--------------------------------------------------

%--------------------------------------------------
\section{Session Information}
%--------------------------------------------------

This vignette was generated using the following package versions:

<<sessionInfo>>=
sessionInfo()
@

%--------------------------------------------------
\section{References}
%--------------------------------------------------
\begingroup
\renewcommand{\section}[2]{}%
\bibliography{refs}
\endgroup


\end{document}


